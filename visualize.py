#!/usr/bin/env python3
"""
æ¯æ¬¡è°ƒç”¨éƒ½ä¼šæ˜¾ç¤ºæ‰€æœ‰å·²å®Œæˆåˆ†å¸ƒçš„è®­ç»ƒç»“æœ
ä½¿ç”¨æ–¹æ³•: python visualize.py
"""

import re
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
from pathlib import Path
import os
import argparse


def parse_training_log(log_path):
    """è§£æè®­ç»ƒæ—¥å¿—æ–‡ä»¶"""
    
    rounds = []
    accuracies = []
    losses = []
    timestamps = []
    
    # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    round_pattern = r'Round\s+(\d+)\s+\|\s+Acc:\s+([\d.]+)\s+\|\s+Loss:\s+([\d.]+)'
    timestamp_pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),(\d{3})'
    
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            for line in f:
                round_match = re.search(round_pattern, line)
                if round_match:
                    timestamp_match = re.search(timestamp_pattern, line)
                    if timestamp_match:
                        timestamp_str = timestamp_match.group(1)
                        timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                        
                        round_num = int(round_match.group(1))
                        accuracy = float(round_match.group(2))
                        loss = float(round_match.group(3))
                        
                        rounds.append(round_num)
                        accuracies.append(accuracy)
                        losses.append(loss)
                        timestamps.append(timestamp)
    
    except Exception as e:
        print(f"Error parsing {log_path}: {e}")
        return None
    
    if not rounds:
        return None
    
    # è®¡ç®—æ—¶é—´æ•°æ®
    wall_clock_times = []
    training_times = []
    
    if timestamps:
        start_time = timestamps[0]
        
        # ç´¯ç§¯æ—¶é—´
        for ts in timestamps:
            elapsed_seconds = (ts - start_time).total_seconds()
            wall_clock_times.append(elapsed_seconds)
        
        # æ¯è½®è®­ç»ƒæ—¶é—´
        for i in range(len(timestamps)):
            if i == 0:
                if len(timestamps) > 1:
                    avg_time = (timestamps[-1] - timestamps[0]).total_seconds() / len(timestamps)
                    training_times.append(avg_time)
                else:
                    training_times.append(0)
            else:
                round_time = (timestamps[i] - timestamps[i-1]).total_seconds()
                training_times.append(round_time)
    
    return {
        'round': rounds,
        'accuracy': accuracies,
        'loss': losses,
        'wall_clock_time': wall_clock_times,
        'training_time': training_times
    }


def load_all_distributions(logs_dir='results/logs'):
    """åŠ è½½æ‰€æœ‰å¯ç”¨åˆ†å¸ƒçš„æ•°æ®"""
    
    logs_path = Path(logs_dir)
    if not logs_path.exists():
        print(f"âŒ Logs directory not found: {logs_dir}")
        return {}
    
    distributions = {}
    distribution_names = ['uniform', 'binomial', 'poisson', 'normal', 'exponential']
    
    print("ğŸ” Scanning for completed experiments...")
    
    for dist_name in distribution_names:
        # æŸ¥æ‰¾è¯¥åˆ†å¸ƒçš„æœ€æ–°æ—¥å¿—æ–‡ä»¶
        log_files = list(logs_path.glob(f"{dist_name}_*.log"))
        
        if log_files:
            # é€‰æ‹©æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
            latest_log = max(log_files, key=lambda x: x.stat().st_mtime)
            print(f"   ğŸ“Š Found {dist_name}: {latest_log.name}")
            
            # è§£ææ•°æ®
            metrics = parse_training_log(latest_log)
            if metrics:
                distributions[dist_name] = metrics
            else:
                print(f"   âš ï¸  Failed to parse {dist_name} data")
        else:
            print(f"   âŒ No data found for {dist_name}")
    
    return distributions


def plot_comparison(distributions, save_dir='results/figures'):

    
    if not distributions:
        print("âŒ No distribution data to plot")
        return None
    
    os.makedirs(save_dir, exist_ok=True)
    
    # åˆ›å»º2x2å­å›¾å¸ƒå±€ - ä¸TIFLå®Œå…¨ä¸€è‡´
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # å®šä¹‰é¢œè‰²æ–¹æ¡ˆ - æ¯ä¸ªåˆ†å¸ƒä¸€ä¸ªé¢œè‰²
    colors = {
        'uniform': '#1f77b4',      # è“è‰²
        'binomial': '#ff7f0e',     # æ©™è‰²  
        'poisson': '#2ca02c',      # ç»¿è‰²
        'normal': '#d62728',       # çº¢è‰²
        'exponential': '#9467bd'   # ç´«è‰²
    }
    
    print(f"\nğŸ“Š Plotting {len(distributions)} distributions: {list(distributions.keys())}")
    
    for dist_name, metrics in distributions.items():
        color = colors.get(dist_name, '#7f7f7f')  # é»˜è®¤ç°è‰²
        
        # 1. Accuracy over rounds (å·¦ä¸Š)
        axes[0, 0].plot(metrics['round'], metrics['accuracy'], 
                       label=dist_name, linewidth=2, color=color)
        
        # 2. Loss over rounds (å³ä¸Š)
        axes[0, 1].plot(metrics['round'], metrics['loss'], 
                       label=dist_name, linewidth=2, color=color)
        
        # 3. Accuracy over time (å·¦ä¸‹)
        axes[1, 0].plot(metrics['wall_clock_time'], metrics['accuracy'], 
                       label=dist_name, linewidth=2, color=color)
        
        # 4. Training time per round (å³ä¸‹)
        axes[1, 1].plot(metrics['round'], metrics['training_time'], 
                       label=dist_name, linewidth=2, color=color)
    
    # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾ - å®Œå…¨æŒ‰ç…§TIFLæ ¼å¼
    axes[0, 0].set_xlabel('Round')
    axes[0, 0].set_ylabel('Test Accuracy')
    axes[0, 0].set_title('Accuracy vs Round')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    axes[0, 1].set_xlabel('Round')
    axes[0, 1].set_ylabel('Test Loss')
    axes[0, 1].set_title('Loss vs Round')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    axes[1, 0].set_xlabel('Wall-clock Time (s)')
    axes[1, 0].set_ylabel('Test Accuracy')
    axes[1, 0].set_title('Accuracy vs Time')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    axes[1, 1].set_xlabel('Round')
    axes[1, 1].set_ylabel('Training Time (s)')
    axes[1, 1].set_title('Training Time per Round')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    # è®¾ç½®æ€»æ ‡é¢˜
    plt.suptitle('Federated Learning - Distribution Comparison', fontsize=16)
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f"{save_dir}/federated_comparison_{timestamp}.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š Plot saved to {save_path}")
    
    # æ˜¾ç¤ºå›¾ç‰‡
    plt.show()
    plt.close()
    
    return save_path


def print_summary(distributions):
    """æ‰“å°æ‰€æœ‰åˆ†å¸ƒçš„æ‘˜è¦ä¿¡æ¯"""
    
    print(f"\n{'='*70}")
    print("ğŸ“Š FEDERATED LEARNING EXPERIMENT SUMMARY")
    print(f"{'='*70}")
    
    if not distributions:
        print("âŒ No completed experiments found")
        return
    
    print(f"ğŸ¯ Completed Distributions: {len(distributions)}")
    print(f"ğŸ“‹ Available: {', '.join(distributions.keys())}")
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    print(f"\nğŸ“ˆ Performance Comparison:")
    print("-" * 70)
    print(f"{'Distribution':<12} {'Rounds':<8} {'Final Acc':<12} {'Best Acc':<12} {'Time(min)':<10}")
    print("-" * 70)
    
    best_acc_dist = ""
    best_acc_value = 0
    fastest_dist = ""
    fastest_time = float('inf')
    
    for dist_name, metrics in distributions.items():
        rounds = len(metrics['round'])
        final_acc = metrics['accuracy'][-1]
        best_acc = max(metrics['accuracy'])
        total_time = metrics['wall_clock_time'][-1] / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        print(f"{dist_name:<12} {rounds:<8} {final_acc:<12.4f} {best_acc:<12.4f} {total_time:<10.1f}")
        
        # è·Ÿè¸ªæœ€ä½³æ€§èƒ½
        if best_acc > best_acc_value:
            best_acc_value = best_acc
            best_acc_dist = dist_name
        
        if total_time < fastest_time:
            fastest_time = total_time
            fastest_dist = dist_name
    
    print("-" * 70)
    print(f"ğŸ† Best Accuracy: {best_acc_dist} ({best_acc_value:.4f})")
    print(f"âš¡ Fastest Training: {fastest_dist} ({fastest_time:.1f} min)")
    
    # æ”¶æ•›åˆ†æ
    print(f"\nğŸ¯ Convergence Analysis:")
    for dist_name, metrics in distributions.items():
        accuracies = metrics['accuracy']
        if len(accuracies) >= 20:
            # è®¡ç®—å20%çš„æ ‡å‡†å·®æ¥åˆ¤æ–­æ”¶æ•›
            last_20_percent = int(len(accuracies) * 0.2)
            recent_std = np.std(accuracies[-last_20_percent:])
            
            if recent_std < 0.001:
                status = "âœ… Converged"
            elif recent_std < 0.005:
                status = "ğŸŸ¡ Nearly Converged"
            else:
                status = "ğŸ”„ Still Learning"
            
            print(f"   {dist_name:<12}: {status} (std: {recent_std:.6f})")
    
    print(f"{'='*70}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Visualize federated learning experiments')
    parser.add_argument('--logs-dir', type=str, default='results/logs',
                       help='Directory containing log files')
    parser.add_argument('--save-dir', type=str, default='results/figures',
                       help='Directory to save plots')
    
    args = parser.parse_args()
    
    print("ğŸ¨ Federated Learning Visualization Tool")
    print("=" * 50)
    print("ğŸ“ Automatically detecting completed experiments...")
    
    # åŠ è½½æ‰€æœ‰å¯ç”¨çš„åˆ†å¸ƒæ•°æ®
    distributions = load_all_distributions(args.logs_dir)
    
    if not distributions:
        print("\nâŒ No completed experiments found!")
        print("ğŸ’¡ Run experiments first:")
        print("   python run_uniform.py")
        print("   python run_poisson.py") 
        print("   python run_binomial.py")
        print("   etc.")
        return
    
    # æ‰“å°æ‘˜è¦
    print_summary(distributions)
    
    # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    print(f"\nğŸ¨ Generating comparison plot...")
    plot_path = plot_comparison(distributions, args.save_dir)
    
    if plot_path:
        print(f"\nğŸ‰ Visualization complete!")
        print(f"ğŸ“Š Comparison plot: {plot_path}")
        print(f"ğŸ“ˆ Showing {len(distributions)} distributions")
        
        # æç¤ºä¸‹ä¸€æ­¥
        remaining_dists = set(['uniform', 'binomial', 'poisson', 'normal', 'exponential']) - set(distributions.keys())
        if remaining_dists:
            print(f"\nğŸ’¡ To add more distributions, run:")
            for dist in sorted(remaining_dists):
                print(f"   python run_{dist}.py")
            print("   python visualize.py  # to update the plot")


if __name__ == '__main__':
    main()
