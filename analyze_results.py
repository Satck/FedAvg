#!/usr/bin/env python3
"""
åˆ†æè”é‚¦å­¦ä¹ å®éªŒç»“æœ - çº¯æ–‡æœ¬ç‰ˆæœ¬
ä¸ä¾èµ–matplotlibï¼Œä¸“é—¨ç”¨äºåˆ†ææ›²çº¿é‡åˆé—®é¢˜
"""

import re
from pathlib import Path
from datetime import datetime


def parse_training_log(log_path):
    """è§£æè®­ç»ƒæ—¥å¿—æ–‡ä»¶"""
    
    rounds = []
    accuracies = []
    losses = []
    timestamps = []
    
    # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    round_pattern = r'Round\s+(\d+)\s+\|\s+Acc:\s+([\d.]+)\s+\|\s+Loss:\s+([\d.]+)'
    timestamp_pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}),(\d{3})'
    
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            for line in f:
                round_match = re.search(round_pattern, line)
                if round_match:
                    timestamp_match = re.search(timestamp_pattern, line)
                    if timestamp_match:
                        timestamp_str = timestamp_match.group(1)
                        timestamp = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
                        
                        round_num = int(round_match.group(1))
                        accuracy = float(round_match.group(2))
                        loss = float(round_match.group(3))
                        
                        rounds.append(round_num)
                        accuracies.append(accuracy)
                        losses.append(loss)
                        timestamps.append(timestamp)
    
    except Exception as e:
        print(f"Error parsing {log_path}: {e}")
        return None
    
    if not rounds:
        return None
    
    return {
        'round': rounds,
        'accuracy': accuracies,
        'loss': losses,
        'timestamps': timestamps
    }


def load_all_distributions(logs_dir='results/logs'):
    """åŠ è½½æ‰€æœ‰å¯ç”¨åˆ†å¸ƒçš„æ•°æ®"""
    
    logs_path = Path(logs_dir)
    if not logs_path.exists():
        print(f"âŒ Logs directory not found: {logs_dir}")
        return {}
    
    distributions = {}
    distribution_names = ['uniform', 'binomial', 'poisson', 'normal', 'exponential']
    
    print("ğŸ” æ‰«æå·²å®Œæˆçš„å®éªŒ...")
    
    for dist_name in distribution_names:
        # æŸ¥æ‰¾è¯¥åˆ†å¸ƒçš„æœ€æ–°æ—¥å¿—æ–‡ä»¶
        log_files = list(logs_path.glob(f"{dist_name}_*.log"))
        
        if log_files:
            # é€‰æ‹©æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
            latest_log = max(log_files, key=lambda x: x.stat().st_mtime)
            print(f"   ğŸ“Š å‘ç° {dist_name}: {latest_log.name}")
            
            # è§£ææ•°æ®
            metrics = parse_training_log(latest_log)
            if metrics:
                distributions[dist_name] = metrics
            else:
                print(f"   âš ï¸  è§£æå¤±è´¥ {dist_name}")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°æ•°æ® {dist_name}")
    
    return distributions


def analyze_accuracy_differences(distributions):
    """æ·±å…¥åˆ†æå‡†ç¡®ç‡å·®å¼‚"""
    
    print(f"\n{'='*80}")
    print("ğŸ” è¯¦ç»†çš„å‡†ç¡®ç‡å·®å¼‚åˆ†æ")
    print(f"{'='*80}")
    
    if len(distributions) < 2:
        print("âŒ éœ€è¦è‡³å°‘2ä¸ªåˆ†å¸ƒè¿›è¡Œæ¯”è¾ƒ")
        return
    
    # 1. åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
    print(f"{'åˆ†å¸ƒ':<12} {'è½®æ•°':<8} {'æœ€ç»ˆå‡†ç¡®ç‡':<12} {'æœ€ä½³å‡†ç¡®ç‡':<12} {'æ ‡å‡†å·®':<12} {'å˜åŒ–èŒƒå›´':<12}")
    print("-" * 80)
    
    final_accs = {}
    best_accs = {}
    
    for dist_name, metrics in distributions.items():
        acc = metrics['accuracy']
        final_acc = acc[-1]
        best_acc = max(acc)
        std_dev = sum((x - sum(acc)/len(acc))**2 for x in acc) / len(acc)  # æ‰‹åŠ¨è®¡ç®—æ ‡å‡†å·®
        std_dev = std_dev ** 0.5
        acc_range = max(acc) - min(acc)
        
        final_accs[dist_name] = final_acc
        best_accs[dist_name] = best_acc
        
        print(f"{dist_name:<12} {len(acc):<8} {final_acc:<12.6f} {best_acc:<12.6f} {std_dev:<12.6f} {acc_range:<12.6f}")
    
    # 2. è½®æ¬¡å·®å¼‚åˆ†æ
    print(f"\nğŸ¯ å…³é”®è½®æ¬¡çš„å‡†ç¡®ç‡å¯¹æ¯”:")
    
    # è·å–æ‰€æœ‰åˆ†å¸ƒå…±åŒçš„è½®æ•°
    min_rounds = min(len(metrics['accuracy']) for metrics in distributions.values())
    
    key_rounds = [1, min_rounds//4, min_rounds//2, min_rounds*3//4, min_rounds]
    
    for round_idx in key_rounds:
        if round_idx <= 0 or round_idx > min_rounds:
            continue
            
        print(f"\nç¬¬ {round_idx} è½®:")
        round_accs = []
        for dist_name, metrics in distributions.items():
            acc_val = metrics['accuracy'][round_idx-1]  # 0-based index
            round_accs.append(acc_val)
            print(f"   {dist_name:>10}: {acc_val:.6f}")
        
        if len(round_accs) > 1:
            acc_min, acc_max = min(round_accs), max(round_accs)
            diff_range = acc_max - acc_min
            print(f"   {'å·®å¼‚èŒƒå›´':>10}: {diff_range:.6f} ({diff_range*100:.4f}%)")
    
    # 3. æ”¶æ•›æ€§åˆ†æ
    print(f"\nğŸ¯ æ”¶æ•›æ€§åˆ†æ (æœ€å20%è½®æ¬¡çš„ç¨³å®šæ€§):")
    for dist_name, metrics in distributions.items():
        accuracies = metrics['accuracy']
        if len(accuracies) >= 20:
            # è®¡ç®—å20%çš„æ ‡å‡†å·®
            last_20_percent = int(len(accuracies) * 0.2)
            recent_accs = accuracies[-last_20_percent:]
            
            # æ‰‹åŠ¨è®¡ç®—æ ‡å‡†å·®
            mean_acc = sum(recent_accs) / len(recent_accs)
            variance = sum((x - mean_acc)**2 for x in recent_accs) / len(recent_accs)
            recent_std = variance ** 0.5
            
            if recent_std < 0.001:
                status = "âœ… å·²æ”¶æ•›"
            elif recent_std < 0.005:
                status = "ğŸŸ¡ æ¥è¿‘æ”¶æ•›"
            else:
                status = "ğŸ”„ ä»åœ¨å­¦ä¹ "
            
            print(f"   {dist_name:<12}: {status} (std: {recent_std:.6f})")


def analyze_learning_patterns(distributions):
    """åˆ†æå­¦ä¹ æ¨¡å¼"""
    
    print(f"\nğŸ§  å­¦ä¹ æ¨¡å¼åˆ†æ:")
    print("-" * 50)
    
    for dist_name, metrics in distributions.items():
        accuracies = metrics['accuracy']
        
        if len(accuracies) < 10:
            continue
        
        # è®¡ç®—å­¦ä¹ é€Ÿåº¦ï¼ˆå‰10è½®çš„æ”¹è¿›ç‡ï¼‰
        early_improvement = accuracies[9] - accuracies[0] if len(accuracies) > 9 else 0
        
        # è®¡ç®—åæœŸç¨³å®šæ€§ï¼ˆæœ€å10è½®çš„å˜åŒ–ï¼‰
        if len(accuracies) >= 10:
            late_change = max(accuracies[-10:]) - min(accuracies[-10:])
        else:
            late_change = 0
        
        print(f"   {dist_name}:")
        print(f"      åˆå§‹å‡†ç¡®ç‡: {accuracies[0]:.6f}")
        print(f"      å‰10è½®æ”¹è¿›: {early_improvement:.6f}")
        print(f"      åæœŸç¨³å®šæ€§: {late_change:.6f} (å˜åŒ–èŒƒå›´)")


def find_potential_causes(distributions):
    """åˆ†æå¯èƒ½çš„åŸå› """
    
    print(f"\nğŸ” é—®é¢˜è¯Šæ–­:")
    print("-" * 50)
    
    # æ£€æŸ¥æ•°æ®ç›¸ä¼¼æ€§
    all_final_accs = [metrics['accuracy'][-1] for metrics in distributions.values()]
    
    if len(all_final_accs) > 1:
        acc_min, acc_max = min(all_final_accs), max(all_final_accs)
        total_range = acc_max - acc_min
        
        print(f"ğŸ“Š æœ€ç»ˆå‡†ç¡®ç‡åˆ†å¸ƒ:")
        print(f"   æœ€ä½: {acc_min:.6f}")
        print(f"   æœ€é«˜: {acc_max:.6f}")
        print(f"   èŒƒå›´: {total_range:.6f} ({total_range*100:.4f}%)")
        
        if total_range < 0.001:  # 0.1%å·®å¼‚
            print("\nâŒ é—®é¢˜ç¡®è®¤: æ‰€æœ‰åˆ†å¸ƒçš„ç»“æœå‡ ä¹ç›¸åŒ!")
            print("å¯èƒ½çš„åŸå› :")
            print("1. ğŸ² æ‰€æœ‰å®éªŒä½¿ç”¨äº†ç›¸åŒçš„éšæœºç§å­")
            print("2. ğŸ“Š æ•°æ®æ˜¯IIDåˆ†å¸ƒï¼Œä¸åŒå®¢æˆ·ç«¯é€‰æ‹©ç­–ç•¥å½±å“å¾ˆå°")
            print("3. ğŸ”§ æ¨¡å‹åˆå§‹åŒ–ç›¸åŒ")
            print("4. âš™ï¸ è¶…å‚æ•°è®¾ç½®ç›¸åŒ")
            
            print(f"\nğŸ’¡ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
            print("1. ä½¿ç”¨ä¸åŒçš„éšæœºç§å­")
            print("2. åˆ›å»ºnon-IIDæ•°æ®åˆ†å¸ƒ")
            print("3. è°ƒæ•´å®¢æˆ·ç«¯é€‰æ‹©ç­–ç•¥çš„å‚æ•°")
            print("4. å¢åŠ å®éªŒçš„å·®å¼‚æ€§è®¾ç½®")
        
        elif total_range < 0.01:  # 1%å·®å¼‚
            print(f"\nâš ï¸ å·®å¼‚è¾ƒå°ä½†å­˜åœ¨ ({total_range*100:.4f}%)")
            print("å»ºè®®: æ”¾å¤§å›¾è¡¨yè½´èŒƒå›´ä»¥æ˜¾ç¤ºå¾®å°å·®å¼‚")
        
        else:
            print(f"\nâœ… å‘ç°æ˜æ˜¾å·®å¼‚ ({total_range*100:.4f}%)")


def main():
    """ä¸»å‡½æ•°"""
    
    print("ğŸ” è”é‚¦å­¦ä¹ ç»“æœåˆ†æå·¥å…· (çº¯æ–‡æœ¬ç‰ˆ)")
    print("="*60)
    
    # åŠ è½½æ‰€æœ‰å¯ç”¨çš„åˆ†å¸ƒæ•°æ®
    distributions = load_all_distributions('results/logs')
    
    if not distributions:
        print("\nâŒ æœªæ‰¾åˆ°å·²å®Œæˆçš„å®éªŒ!")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œå®éªŒ:")
        print("   python run_uniform.py")
        print("   python run_binomial.py")
        print("   ç­‰ç­‰...")
        return
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(distributions)} ä¸ªåˆ†å¸ƒçš„æ•°æ®:")
    for dist_name in distributions.keys():
        print(f"   ğŸ“Š {dist_name}")
    
    # æ‰§è¡Œè¯¦ç»†åˆ†æ
    analyze_accuracy_differences(distributions)
    analyze_learning_patterns(distributions)
    find_potential_causes(distributions)
    
    print(f"\n{'='*60}")
    print("ğŸ‰ åˆ†æå®Œæˆ!")
    print("ğŸ“‹ åŸºäºä»¥ä¸Šåˆ†æï¼Œæ‚¨å¯ä»¥:")
    print("   1. ä¿®æ”¹å®éªŒè®¾ç½®ä»¥äº§ç”Ÿæ›´æ˜æ˜¾çš„å·®å¼‚")
    print("   2. è°ƒæ•´å¯è§†åŒ–ä»£ç ä»¥æ”¾å¤§å¾®å°å·®å¼‚")
    print("   3. ä½¿ç”¨non-IIDæ•°æ®åˆ†å¸ƒ")


if __name__ == '__main__':
    main()
