# analyze_selection_patterns.py
# åˆ†ææ¯ä¸ªåˆ†å¸ƒçš„å®¢æˆ·ç«¯é€‰æ‹©æ¨¡å¼

import sys
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Helvetica', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# å¯¹äºç»Ÿè®¡æ‘˜è¦ï¼Œä½¿ç”¨ç­‰å®½å­—ä½“ä½†é¿å…ä¸­æ–‡å­—ç¬¦é—®é¢˜
import matplotlib.font_manager as fm
try:
    # å°è¯•æ‰¾åˆ°æ”¯æŒä¸­æ–‡çš„å­—ä½“
    chinese_fonts = [f.name for f in fm.fontManager.ttflist if 'SimHei' in f.name or 'Arial Unicode MS' in f.name]
    if chinese_fonts:
        plt.rcParams['font.sans-serif'] = chinese_fonts + ['Helvetica', 'DejaVu Sans']
except:
    pass

def analyze_distribution(distribution_name):
    """åˆ†æå•ä¸ªåˆ†å¸ƒçš„é€‰æ‹©æ¨¡å¼"""
    
    result_file = f"results/{distribution_name}_results.pt"
    
    if not os.path.exists(result_file):
        print(f"âŒ æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶: {result_file}")
        return None
    
    # åŠ è½½ç»“æœ
    results = torch.load(result_file, weights_only=False)
    selection_stats = results['selection_stats']
    selection_counts = selection_stats['selection_counts']
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {distribution_name.upper()} åˆ†å¸ƒé€‰æ‹©åˆ†æ")
    print(f"{'='*60}")
    print(f"æ€»è½®æ•°: {selection_stats['total_rounds']}")
    print(f"å¹³å‡é€‰æ‹©æ¬¡æ•°: {selection_stats['mean']:.2f}")
    print(f"æ ‡å‡†å·®: {selection_stats['std']:.2f}")
    print(f"æœ€å¤§é€‰æ‹©æ¬¡æ•°: {selection_stats['max']}")
    print(f"æœ€å°é€‰æ‹©æ¬¡æ•°: {selection_stats['min']}")
    print(f"å…¬å¹³æ€§æ¯”ç‡ (max/min): {selection_stats['max']/max(selection_stats['min'],1):.2f}")
    
    # ç»Ÿè®¡é€‰æ‹©æ¬¡æ•°åˆ†å¸ƒ
    unique, counts = np.unique(selection_counts.astype(int), return_counts=True)
    print(f"\né€‰æ‹©æ¬¡æ•°åˆ†å¸ƒ:")
    for times, count in zip(unique[:10], counts[:10]):  # æ˜¾ç¤ºå‰10ä¸ª
        print(f"  è¢«é€‰{times}æ¬¡: {count}ä¸ªå®¢æˆ·ç«¯")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å®¢æˆ·ç«¯ä»æœªè¢«é€‰ä¸­
    never_selected = np.sum(selection_counts == 0)
    if never_selected > 0:
        print(f"\nâš ï¸  è­¦å‘Š: æœ‰ {never_selected} ä¸ªå®¢æˆ·ç«¯ä»æœªè¢«é€‰ä¸­!")
        print(f"æœªé€‰ä¸­çš„å®¢æˆ·ç«¯ID: {np.where(selection_counts == 0)[0].tolist()}")
    
    # æ£€æŸ¥é€‰æ‹©æœ€å¤šå’Œæœ€å°‘çš„å®¢æˆ·ç«¯
    most_selected = np.argsort(selection_counts)[-5:][::-1]
    least_selected = np.argsort(selection_counts)[:5]
    
    print(f"\né€‰æ‹©æœ€å¤šçš„5ä¸ªå®¢æˆ·ç«¯:")
    for client_id in most_selected:
        print(f"  å®¢æˆ·ç«¯ {client_id}: è¢«é€‰ {int(selection_counts[client_id])} æ¬¡")
    
    print(f"\né€‰æ‹©æœ€å°‘çš„5ä¸ªå®¢æˆ·ç«¯:")
    for client_id in least_selected:
        print(f"  å®¢æˆ·ç«¯ {client_id}: è¢«é€‰ {int(selection_counts[client_id])} æ¬¡")
    
    return {
        'name': distribution_name,
        'counts': selection_counts,
        'stats': selection_stats
    }


def visualize_selection_patterns(all_data):
    """å¯è§†åŒ–æ‰€æœ‰åˆ†å¸ƒçš„é€‰æ‹©æ¨¡å¼"""
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('å®¢æˆ·ç«¯é€‰æ‹©æ¨¡å¼å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
    
    colors = {
        'uniform': '#1f77b4',
        'binomial': '#ff7f0e', 
        'poisson': '#2ca02c',
        'normal': '#d62728',
        'exponential': '#9467bd'
    }
    
    # 1. ç›´æ–¹å›¾ï¼šé€‰æ‹©æ¬¡æ•°åˆ†å¸ƒ
    ax1 = axes[0, 0]
    for data in all_data:
        ax1.hist(data['counts'], bins=30, alpha=0.5, 
                label=data['name'], color=colors[data['name']])
    ax1.set_xlabel('é€‰æ‹©æ¬¡æ•°')
    ax1.set_ylabel('å®¢æˆ·ç«¯æ•°é‡')
    ax1.set_title('é€‰æ‹©æ¬¡æ•°åˆ†å¸ƒç›´æ–¹å›¾')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. ç®±çº¿å›¾ï¼šé€‰æ‹©æ¬¡æ•°ç»Ÿè®¡
    ax2 = axes[0, 1]
    box_data = [data['counts'] for data in all_data]
    box_labels = [data['name'] for data in all_data]
    bp = ax2.boxplot(box_data, tick_labels=box_labels, patch_artist=True)
    for patch, name in zip(bp['boxes'], box_labels):
        patch.set_facecolor(colors[name])
        patch.set_alpha(0.6)
    ax2.set_ylabel('é€‰æ‹©æ¬¡æ•°')
    ax2.set_title('é€‰æ‹©æ¬¡æ•°ç®±çº¿å›¾')
    ax2.grid(True, alpha=0.3)
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
    
    # 3. æŸ±çŠ¶å›¾ï¼šå…¬å¹³æ€§æŒ‡æ ‡
    ax3 = axes[0, 2]
    fairness_ratios = [data['stats']['max']/max(data['stats']['min'],1) 
                       for data in all_data]
    bars = ax3.bar(range(len(all_data)), fairness_ratios, 
                   color=[colors[d['name']] for d in all_data])
    ax3.set_xticks(range(len(all_data)))
    ax3.set_xticklabels([d['name'] for d in all_data], rotation=45)
    ax3.set_ylabel('å…¬å¹³æ€§æ¯”ç‡ (max/min)')
    ax3.set_title('é€‰æ‹©å…¬å¹³æ€§å¯¹æ¯” (è¶Šå°è¶Šå…¬å¹³)')
    ax3.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='å®Œå…¨å…¬å¹³')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, ratio) in enumerate(zip(bars, fairness_ratios)):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{ratio:.2f}', ha='center', va='bottom', fontsize=9)
    
    # 4. æŠ˜çº¿å›¾ï¼šæŒ‰å®¢æˆ·ç«¯IDçš„é€‰æ‹©æ¬¡æ•°
    ax4 = axes[1, 0]
    for data in all_data:
        ax4.plot(range(len(data['counts'])), data['counts'], 
                label=data['name'], color=colors[data['name']], alpha=0.7)
    ax4.set_xlabel('å®¢æˆ·ç«¯ID')
    ax4.set_ylabel('é€‰æ‹©æ¬¡æ•°')
    ax4.set_title('å„å®¢æˆ·ç«¯é€‰æ‹©æ¬¡æ•°æ›²çº¿')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    # 5. çƒ­åŠ›å›¾ï¼šé€‰æ‹©æ¬¡æ•°ï¼ˆä»…æ˜¾ç¤ºå‰50ä¸ªå®¢æˆ·ç«¯ï¼‰
    ax5 = axes[1, 1]
    heatmap_data = np.array([data['counts'][:50] for data in all_data])
    im = ax5.imshow(heatmap_data, aspect='auto', cmap='YlOrRd')
    ax5.set_yticks(range(len(all_data)))
    ax5.set_yticklabels([d['name'] for d in all_data])
    ax5.set_xlabel('å®¢æˆ·ç«¯ID (å‰50ä¸ª)')
    ax5.set_title('é€‰æ‹©æ¬¡æ•°çƒ­åŠ›å›¾')
    plt.colorbar(im, ax=ax5, label='é€‰æ‹©æ¬¡æ•°')
    
    # 6. ç»Ÿè®¡æ‘˜è¦
    ax6 = axes[1, 2]
    ax6.axis('off')
    
    summary_text = "ç»Ÿè®¡æ‘˜è¦\n" + "="*40 + "\n\n"
    for data in all_data:
        stats = data['stats']
        summary_text += f"{data['name'].upper()}:\n"
        summary_text += f"  å‡å€¼: {stats['mean']:.2f}\n"
        summary_text += f"  æ ‡å‡†å·®: {stats['std']:.2f}\n"
        summary_text += f"  èŒƒå›´: [{stats['min']}, {stats['max']}]\n"
        summary_text += f"  å…¬å¹³æ€§: {stats['max']/max(stats['min'],1):.2f}\n\n"
    
    ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes,
            fontsize=10, verticalalignment='top', fontfamily='sans-serif',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_dir = Path("results/figures")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_file = output_dir / "client_selection_analysis.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"\nâœ… åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: {output_file}")
    
    plt.show()


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ” å®¢æˆ·ç«¯é€‰æ‹©æ¨¡å¼åˆ†æå·¥å…·")
    print("="*60)
    
    distributions = ['uniform', 'binomial', 'poisson', 'normal', 'exponential']
    all_data = []
    
    for dist in distributions:
        data = analyze_distribution(dist)
        if data:
            all_data.append(data)
    
    if len(all_data) >= 2:
        print(f"\n{'='*60}")
        print("ğŸ“Š å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å¯¹æ¯”å›¾...")
        print(f"{'='*60}")
        visualize_selection_patterns(all_data)
    else:
        print("\nâš ï¸  è‡³å°‘éœ€è¦2ä¸ªåˆ†å¸ƒçš„ç»“æœæ‰èƒ½è¿›è¡Œå¯¹æ¯”åˆ†æ")
    
    print("\nâœ… åˆ†æå®Œæˆ!")


if __name__ == '__main__':
    main()

