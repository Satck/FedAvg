# src/algorithms/fedavg.py

import torch
import torch.nn as nn
import torch.optim as optim
import copy
import numpy as np
from typing import List, Dict, Any, Tuple
from tqdm import tqdm


class FederatedAveraging:
    """
    è”é‚¦å¹³å‡ç®—æ³•ï¼ˆFedAvgï¼‰
    
    å‚è€ƒè®ºæ–‡Algorithm 1ï¼ˆç¬¬5é¡µï¼‰
    """
    
    def __init__(self,
                 model: nn.Module,
                 client_loaders: List[torch.utils.data.DataLoader],
                 test_loader: torch.utils.data.DataLoader,
                 client_selector,
                 config: Dict[str, Any]):
        """
        åˆå§‹åŒ–FedAvgç®—æ³•
        
        Args:
            model: å…¨å±€æ¨¡å‹
            client_loaders: å®¢æˆ·ç«¯æ•°æ®åŠ è½½å™¨åˆ—è¡¨
            test_loader: æµ‹è¯•é›†åŠ è½½å™¨
            client_selector: å®¢æˆ·ç«¯é€‰æ‹©å™¨
            config: é…ç½®å­—å…¸
        """
        self.global_model = model
        self.client_loaders = client_loaders
        self.test_loader = test_loader
        self.client_selector = client_selector
        self.config = config
        
        # è¶…å‚æ•°
        self.num_clients = len(client_loaders)
        self.clients_per_round = config['clients_per_round']
        self.local_epochs = config['local_epochs']  # E
        self.learning_rate = config['learning_rate']  # Î·
        self.device = config['device']
        
        # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡
        self.global_model.to(self.device)
        
        # è®­ç»ƒå†å²
        self.history = {
            'rounds': [],
            'train_loss': [],
            'test_acc': [],
            'test_loss': []
        }
        
        print(f"FedAvgåˆå§‹åŒ–å®Œæˆ")
        print(f"  - å®¢æˆ·ç«¯æ€»æ•°: {self.num_clients}")
        print(f"  - æ¯è½®é€‰æ‹©: {self.clients_per_round}")
        print(f"  - æœ¬åœ°epoch: {self.local_epochs}")
        print(f"  - å­¦ä¹ ç‡: {self.learning_rate}")
        print(f"  - è®¾å¤‡: {self.device}")
    
    def client_update(self, 
                      client_id: int, 
                      global_weights: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        å®¢æˆ·ç«¯æœ¬åœ°æ›´æ–°ï¼ˆAlgorithm 1ä¸­çš„ClientUpdateï¼‰
        
        Args:
            client_id: å®¢æˆ·ç«¯ID
            global_weights: å…¨å±€æ¨¡å‹å‚æ•°
            
        Returns:
            updated_weights: æ›´æ–°åçš„æ¨¡å‹å‚æ•°
        """
        # åˆ›å»ºæœ¬åœ°æ¨¡å‹å‰¯æœ¬
        local_model = copy.deepcopy(self.global_model)
        local_model.load_state_dict(global_weights)
        local_model.train()
        
        # æœ¬åœ°ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨SGDï¼Œæ— momentumï¼‰
        optimizer = optim.SGD(local_model.parameters(), lr=self.learning_rate)
        criterion = nn.CrossEntropyLoss()
        
        # æœ¬åœ°è®­ç»ƒEä¸ªepoch
        for epoch in range(self.local_epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_idx, (data, target) in enumerate(self.client_loaders[client_id]):
                data, target = data.to(self.device), target.to(self.device)
                
                # å‰å‘ä¼ æ’­
                optimizer.zero_grad()
                output = local_model(data)
                loss = criterion(output, target)
                
                # åå‘ä¼ æ’­
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
        
        # è¿”å›æ›´æ–°åçš„æ¨¡å‹å‚æ•°
        return local_model.state_dict()
    
    def aggregate_models(self, 
                        client_weights_list: List[Dict[str, torch.Tensor]], 
                        client_data_sizes: List[int]) -> None:
        """
        èšåˆå®¢æˆ·ç«¯æ¨¡å‹ï¼ˆåŠ æƒå¹³å‡ï¼‰
        
        Args:
            client_weights_list: å®¢æˆ·ç«¯æ¨¡å‹å‚æ•°åˆ—è¡¨
            client_data_sizes: å®¢æˆ·ç«¯æ•°æ®é‡åˆ—è¡¨
        """
        # è®¡ç®—æ€»æ•°æ®é‡
        total_size = sum(client_data_sizes)
        
        # åŠ æƒå¹³å‡
        global_weights = self.global_model.state_dict()
        
        # åˆå§‹åŒ–ä¸ºé›¶
        for key in global_weights.keys():
            global_weights[key] = torch.zeros_like(global_weights[key])
        
        # åŠ æƒæ±‚å’Œ
        for client_weights, data_size in zip(client_weights_list, client_data_sizes):
            weight = data_size / total_size
            for key in global_weights.keys():
                global_weights[key] += client_weights[key] * weight
        
        # æ›´æ–°å…¨å±€æ¨¡å‹
        self.global_model.load_state_dict(global_weights)
    
    def evaluate(self) -> Tuple[float, float]:
        """
        è¯„ä¼°å…¨å±€æ¨¡å‹
        
        Returns:
            accuracy: æµ‹è¯•å‡†ç¡®ç‡
            loss: æµ‹è¯•æŸå¤±
        """
        self.global_model.eval()
        test_loss = 0.0
        correct = 0
        total = 0
        
        criterion = nn.CrossEntropyLoss()
        
        with torch.no_grad():
            for data, target in self.test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.global_model(data)
                
                # ç´¯è®¡æŸå¤±
                test_loss += criterion(output, target).item()
                
                # ç»Ÿè®¡å‡†ç¡®ç‡
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
        
        test_loss /= len(self.test_loader)
        accuracy = correct / total
        
        return accuracy, test_loss
    
    def train_round(self, round_num: int) -> Dict[str, Any]:
        """
        æ‰§è¡Œä¸€è½®è”é‚¦å­¦ä¹ 
        
        Args:
            round_num: å½“å‰è½®æ¬¡
            
        Returns:
            round_info: æœ¬è½®è¯¦ç»†ä¿¡æ¯
        """
        # ä½¿ç”¨å®¢æˆ·ç«¯é€‰æ‹©å™¨é€‰æ‹©å®¢æˆ·ç«¯
        selected_clients = self.client_selector.select(
            num_select=self.clients_per_round,
            round_num=round_num
        )
        
        # è·å–å½“å‰å…¨å±€æ¨¡å‹å‚æ•°
        global_weights = self.global_model.state_dict()
        
        # å®¢æˆ·ç«¯æœ¬åœ°æ›´æ–°
        client_weights_list = []
        client_data_sizes = []
        
        for client_id in selected_clients:
            # å®¢æˆ·ç«¯æ›´æ–°
            updated_weights = self.client_update(client_id, global_weights)
            client_weights_list.append(updated_weights)
            
            # è®°å½•å®¢æˆ·ç«¯æ•°æ®é‡ï¼ˆç”¨äºåŠ æƒå¹³å‡ï¼‰
            data_size = len(self.client_loaders[client_id].dataset)
            client_data_sizes.append(data_size)
        
        # èšåˆæ¨¡å‹
        self.aggregate_models(client_weights_list, client_data_sizes)
        
        # è®°å½•é€‰æ‹©å†å²
        self.client_selector.record_selection(selected_clients, round_num)
        
        # è¿”å›æœ¬è½®ä¿¡æ¯
        return {
            'round': round_num,
            'selected_clients': selected_clients.tolist(),
            'num_selected': len(selected_clients),
            'client_data_sizes': client_data_sizes
        }
    
    def train(self, 
              num_rounds: int, 
              eval_every: int = 10,
              target_accuracy: float = None,
              logger=None) -> Tuple[Dict, Dict]:
        """
        å®Œæ•´è®­ç»ƒæµç¨‹
        
        Args:
            num_rounds: æ€»è®­ç»ƒè½®æ•°
            eval_every: æ¯éš”å¤šå°‘è½®è¯„ä¼°ä¸€æ¬¡
            target_accuracy: ç›®æ ‡å‡†ç¡®ç‡ï¼ˆè¾¾åˆ°åå¯æå‰åœæ­¢ï¼‰
            logger: æ—¥å¿—è®°å½•å™¨
            
        Returns:
            history: è®­ç»ƒå†å²
            selection_stats: å®¢æˆ·ç«¯é€‰æ‹©ç»Ÿè®¡
        """
        # æ‰©å±•å†å²è®°å½•ç»“æ„ï¼Œè®°å½•æ¯è½®è¯¦ç»†æ•°æ®
        detailed_history = {
            'rounds': [],
            'test_acc': [],
            'test_loss': [],
            'selected_clients': [],
            'round_details': []
        }
        
        log_func = logger.info if logger else print
        
        log_func(f"\n{'='*80}")
        log_func(f"å¼€å§‹è®­ç»ƒ")
        log_func(f"  - æ€»è½®æ•°: {num_rounds}")
        log_func(f"  - å®¢æˆ·ç«¯é€‰æ‹©å™¨: {self.client_selector.get_name()}")
        log_func(f"{'='*80}\n")
        
        # åˆå§‹è¯„ä¼°
        init_acc, init_loss = self.evaluate()
        log_func(f"ğŸ“Š åˆå§‹æ€§èƒ½ | Test Acc: {init_acc:.4f} | Test Loss: {init_loss:.4f}")
        log_func("-"*60)
        
        # è®­ç»ƒå¾ªç¯
        for round_num in tqdm(range(1, num_rounds + 1), desc="Training"):
            # è®­ç»ƒä¸€è½®
            round_info = self.train_round(round_num)
            
            # æ¯è½®éƒ½è¿›è¡Œè¯„ä¼°ä»¥è·å¾—å®Œæ•´æ•°æ®
            acc, loss = self.evaluate()
            
            # è®°å½•è¯¦ç»†å†å²
            detailed_history['rounds'].append(round_num)
            detailed_history['test_acc'].append(acc)
            detailed_history['test_loss'].append(loss)
            detailed_history['selected_clients'].append(round_info['selected_clients'])
            detailed_history['round_details'].append(round_info)
            
            # æ¯è½®éƒ½è®°å½•åŸºæœ¬ä¿¡æ¯åˆ°æ—¥å¿—
            selected_clients_str = str(round_info['selected_clients'][:5])  # åªæ˜¾ç¤ºå‰5ä¸ª
            if len(round_info['selected_clients']) > 5:
                selected_clients_str = selected_clients_str[:-1] + ", ...]"
            
            log_func(f"ğŸ”„ Round {round_num:3d} | Acc: {acc:.4f} | Loss: {loss:.4f} | "
                    f"é€‰ä¸­: {selected_clients_str}")
            
            # å®šæœŸæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if round_num % eval_every == 0 or round_num == 1:
                log_func(f"   ğŸ“ˆ è¯¦ç»† Round {round_num:3d} | Test Acc: {acc:.4f} | Test Loss: {loss:.4f}")
                log_func(f"   ğŸ‘¥ é€‰ä¸­å®¢æˆ·ç«¯: {round_info['selected_clients']}")
                log_func(f"   ğŸ“Š é€‰ä¸­æ•°é‡: {len(round_info['selected_clients'])}/{self.num_clients}")
                log_func("-"*60)
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡
                if target_accuracy is not None and acc >= target_accuracy:
                    log_func(f"\nğŸ¯ è¾¾åˆ°ç›®æ ‡å‡†ç¡®ç‡ {target_accuracy:.2%}ï¼Œæå‰åœæ­¢è®­ç»ƒ")
                    break
        
        # æœ€ç»ˆè¯„ä¼°
        final_acc, final_loss = self.evaluate()
        log_func(f"\n{'='*80}")
        log_func(f"ğŸ‰ è®­ç»ƒå®Œæˆ")
        log_func(f"  - æœ€ç»ˆå‡†ç¡®ç‡: {final_acc:.4f}")
        log_func(f"  - æœ€ç»ˆæŸå¤±: {final_loss:.4f}")
        
        # æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹ç»Ÿè®¡
        if len(detailed_history['test_acc']) > 1:
            max_acc = max(detailed_history['test_acc'])
            min_loss = min(detailed_history['test_loss'])
            improvement = detailed_history['test_acc'][-1] - detailed_history['test_acc'][0]
            log_func(f"  - æœ€ä½³å‡†ç¡®ç‡: {max_acc:.4f}")
            log_func(f"  - æœ€ä½æŸå¤±: {min_loss:.4f}")
            log_func(f"  - å‡†ç¡®ç‡æå‡: {improvement:+.4f}")
        
        log_func(f"{'='*80}\n")
        
        # è·å–å®¢æˆ·ç«¯é€‰æ‹©ç»Ÿè®¡
        selection_stats = self.client_selector.get_selection_statistics()
        
        # æ›´æ–°self.historyä¸ºè¯¦ç»†å†å²
        self.history = detailed_history
        
        return detailed_history, selection_stats
